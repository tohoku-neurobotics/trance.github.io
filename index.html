<!DOCTYPE html>
<html lang="en">
  <head>
      <meta charset="UTF-8">
      <link rel="stylesheet" href="main.css">
      <link rel="icon" type="image/x-icon" href="assets/hardware.png">
      <title>TRANS</title>
  </head>
  <body>


    <div id="title_slide">
        <div class="title_left">
            <h1>TRANS: Terrain-aware Reinforcement Learning for <br> Agile Navigation of Quadruped Robots under Social Interactions</h1>
        

            <div class="box alt">
              <div class="row uniform">
                <div class="2u">
                  <a href="https://www.weizhu996.com/">                                
                    <span class="image fit"><img src="assets/author_photo/weizhu.png" alt="Wei Zhu" /></span>Wei Zhu<sup>1</sup>
                  </a>
                </div>
                <div class="2u">
                  <a href="https://titoirfan.github.io/">         
                    <span class="image fit"><img src="assets/author_photo/tito.jpg" alt="Irfan Tito Kurniawan" /></span>Irfan Tito Kurniawan<sup>1</sup>
                  </a>
                </div>
                <div class="2u">
                  <a href="https://research.gatech.edu/people/ye-zhao">   
                    <span class="image fit"><img src="assets/author_photo/ye_zhao.jpg" alt="Ye Zhao" /></span>Ye Zhao<sup>2</sup>
                  </a>
                </div>
                <div class="2u">
                  <a href="https://scholar.google.com/citations?user=2VmKkUkAAAAJ&hl=en&oi=ao">                 
                    <span class="image fit"><img src="assets/author_photo/hayashibe.jpeg" alt="Mistuhiro Hayashibe" /></span>Mistuhiro Hayashibe<sup>1</sup>
                  </a>
                </div>
              </div>
          </div>

            <div class="gatech">
                <p><sup>1</sup>Tohoku University, <sup>2</sup>Georgia Institute of Technology</p>
            </div>
            <div class="button-container">
                <a href="https://arxiv.org/abs/2602.12724" class="button">Paper</a>
                <a href="https://youtu.be/dvNvqVcB9o0" class="button">Video</a>
                <a href="https://github.com/tohoku-neurobotics/trance" class="button">Code</a>
            </div>

            <br>

            <div id="abstract" class="grid-container">
                <p>
                  This study introduces TRANS: Terrain-aware Reinforcement learning for Agile Navigation under Social interactions, a deep reinforcement learning (DRL) framework for quadrupedal social navigation over unstructured terrains. Conventional quadrupedal navigation typically separates motion planning from locomotion control, neglecting whole-body constraints and terrain awareness. On the other hand, end-to-end methods are more integrated but require high-frequency sensing, which is often noisy and computationally costly. In addition, most existing approaches assume static environments, limiting their use in human-populated settings. To address these limitations, we propose a two-stage training framework with three DRL pipelines. (1) TRANS-Loco employs an asymmetric actor–critic (AC) model for quadrupedal locomotion, enabling traversal of uneven terrains without explicit terrain or contact observations. (2) TRANS-Nav applies a symmetric AC framework for social navigation, directly mapping transformed LiDAR data to ego-agent actions under differential-drive kinematics. (3) A unified pipeline, TRANS, integrates TRANS-Loco and TRANS-Nav, supporting terrain-aware quadrupedal navigation in uneven and socially interactive environments. Comprehensive benchmarks against locomotion and social navigation baselines demonstrate the effectiveness of TRANS. Hardware experiments further confirm its potential for sim-to-real transfer.
                </p>
            </div>
        </div>
    </div>
    <hr class="rounded">
    
    <div id="overview">

        <h1>TRANS framework</h1>

        <p>
          Our approach decouples quadrupedal locomotion from crowd navigation by independently training two distinct DRL policies. To ensure reliable locomotion, we first utilize an asymmetric actor–critic (AC) architecture that operates without explicit terrain maps or contact states. By relying strictly on proprioceptive inputs, the policy circumvents the challenges associated with noisy exteroceptive data, thereby streamlining the transition from simulation to real-world deployment. Concurrently, a symmetric AC framework is developed for crowd navigation, employing a differential-drive model governed by kinematic constraints. Subsequently, the crowd navigation policy is fine-tuned and extended for the quadrupedal platform. During this second stage of training, the underlying locomotion policy remains frozen to preserve the learned gait primitives while the higher-level navigation controller is optimized. This integration yields a unified, end-to-end policy capable of robust quadrupedal navigation in uneven and human-populated environments. 
        </p>

        <div style="display: flex; justify-content: center;">
          <iframe 
            width="560" 
            height="315" 
            src="https://www.youtube.com/embed/aTRwGPMBeIg?autoplay=1&mute=1" 
            frameborder="0" 
            allow="autoplay; encrypted-media" 
            allowfullscreen>
          </iframe>
        </div>

        <h1>TRANS-Loco comparison</h1>
        <p>
          In the first stage, we first train a locomotion policy and evaluate the velocity tracking performance.
        </p>

        <div style="display: flex; justify-content: center;">
          <iframe 
            width="560" 
            height="315" 
            src="https://www.youtube.com/embed/KUaYYfePz-k?autoplay=1&mute=1" 
            frameborder="0" 
            allow="autoplay; encrypted-media" 
            allowfullscreen>
          </iframe>
        </div>

        <h1>TRANS-Nav comparison</h1>
        <p>
          In parallel, we train a crowd navigation policy for a differential-drive model.
        </p>

        <div style="display: flex; justify-content: center;">
          <iframe 
            width="560" 
            height="315" 
            src="https://www.youtube.com/embed/FenQuC1l8sc?autoplay=1&mute=1" 
            frameborder="0" 
            allow="autoplay; encrypted-media" 
            allowfullscreen>
          </iframe>
        </div>

        <h1>TRANS: unified quadrupedal navigation policy</h1>
        <p>
          During the second training phase, the locomotion and navigation policies are harmonized, enabling the quadrupedal robot to navigate uneven and crowded spaces concurrently.
        </p>

        <div style="display: flex; justify-content: center;">
          <iframe 
            width="560" 
            height="315" 
            src="https://www.youtube.com/embed/27nYCaDba7k?autoplay=1&mute=1" 
            frameborder="0" 
            allow="autoplay; encrypted-media" 
            allowfullscreen>
          </iframe>
        </div>

        <h1>Sim-to-real</h1>
        <p>
          We evaluated our policy across a diverse range of environments, including indoor flat and uneven surfaces, outdoor cement and grass slopes, and stairs with a 12 cm step height.
        </p>
 
        <div style="display: flex; justify-content: center;">
          <iframe 
            width="560" 
            height="315" 
            src="https://www.youtube.com/embed/LGvcQCSaB7A?autoplay=1&mute=1" 
            frameborder="0" 
            allow="autoplay; encrypted-media" 
            allowfullscreen>
          </iframe>
        </div>

        <script>
          document.addEventListener("DOMContentLoaded", function() {
              document.querySelectorAll(".autoplay-video").forEach(function(iframe) {
                  iframe.src = iframe.getAttribute("data-src"); // Dynamically set the `src`
              });
          });
          </script>
       
        <h1>BibTeX</h1>
         <p class="bibtex">
            @article{zhu2026trans,<br>
            &nbsp;&nbsp;title={TRANS: Terrain-aware Reinforcement Learning for Agile Navigation of Quadruped Robots under Social Interactions},<br>
            &nbsp;&nbsp;author={Wei Zhu, Irfan Tito Kurniawan, Ye Zhao, and Mistuhiro Hayashibe},<br>
            &nbsp;&nbsp;journal={arXiv preprint arXiv:2602.12724}<br>
            &nbsp;&nbsp;year={2026},<br>
            }
        </p>

      
       

        <div class="footer">
          <p>This website was developed based on <a href="https://github.com/learning-humanoid-locomotion/learning-humanoid-locomotion.github.io" target="_blank">learning-humanoid-locomotion</a></p>
      </div>
      
    </div>
    <script type="text/javascript">
        /* https://stackoverflow.com/questions/3027707/how-to-change-the-playing-speed-of-videos-in-html5 */
        document.querySelector('video').defaultPlaybackRate = 1.0;
        document.querySelector('video').play();

        var videos =document.querySelectorAll('video');
        for (var i=0;i<1;i++)
        {
            videos[i].playbackRate = 1.0;
        }
    </script>
    <script>
        /* https://stackoverflow.com/questions/21163756/html5-and-javascript-to-play-videos-only-when-visible */
        var videos = document.getElementsByTagName("video");

        function checkScroll() {
            var fraction = 0.5; // Play when 70% of the player is visible.

            for(var i = 0; i < 1; i++) {  // only apply to the first video

                var video = videos[i];

                var x = video.offsetLeft, y = video.offsetTop, w = video.offsetWidth, h = video.offsetHeight, r = x + w, //right
                    b = y + h, //bottom
                    visibleX, visibleY, visible;

                visibleX = Math.max(0, Math.min(w, window.pageXOffset + window.innerWidth - x, r - window.pageXOffset));
                visibleY = Math.max(0, Math.min(h, window.pageYOffset + window.innerHeight - y, b - window.pageYOffset));

                visible = visibleX * visibleY / (w * h);

                if (visible > fraction) {
                    video.play();
                } else {
                    video.pause();
                }

            }

        }
        window.addEventListener('scroll', checkScroll, false);
        window.addEventListener('resize', checkScroll, false);
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            // Function to check if the user is on a mobile device
            function isMobileDevice() {
                return /Mobi|Android/i.test(navigator.userAgent);
            }
            // If the user is on a mobile device, disable autoplay
            if (isMobileDevice()) {
                const videos = document.querySelectorAll('video');
                videos.forEach(video => {
                    video.autoplay = false;
                    video.controls = true;
                });
            }
        });
    </script>
    <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=51e0d73d83d06baa7a00000f"
            type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
            crossorigin="anonymous"></script>
    <script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.fd002feec.js"
            type="text/javascript"></script>
  </body>

</html>
